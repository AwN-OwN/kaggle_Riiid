{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Setting up competition libraries  \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport riiideducation\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n/kaggle/input/riiid-test-answer-prediction/example_test.csv\n/kaggle/input/riiid-test-answer-prediction/questions.csv\n/kaggle/input/riiid-test-answer-prediction/train.csv\n/kaggle/input/riiid-test-answer-prediction/lectures.csv\n/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing libraries\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as metrics\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport gc","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting global variables \nrandom_seed = 0\ntrain_ratio = 0.8\ntest_ratio = 1-train_ratio \nnum_imp_str = 'median'\n\n#training sample \nsample_size = 18000000 #18% of total\n\n#LightGBM parameters\nparams = {'objective': 'binary',\n          'metric': 'auc',\n          'seed': random_seed,\n          'learning_rate': 0.1, #default\n          \"boosting_type\": \"gbdt\" #default\n         }","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading training data\ntrain = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv',  \n                       dtype={'row_id': 'int64', 'timestamp': 'int64', 'user_id': 'int32', 'content_id': 'int16', 'content_type_id': 'int8',\n                              'task_container_id': 'int16', 'user_answer': 'int8', 'answered_correctly': 'int8', 'prior_question_elapsed_time': 'float32', \n                             'prior_question_had_explanation': 'boolean',\n                             }\n                      )\ntrain = train.set_index('row_id')\ntrain.info()","execution_count":4,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 101230332 entries, 0 to 101230331\nData columns (total 9 columns):\n #   Column                          Dtype  \n---  ------                          -----  \n 0   timestamp                       int64  \n 1   user_id                         int32  \n 2   content_id                      int16  \n 3   content_type_id                 int8   \n 4   task_container_id               int16  \n 5   user_answer                     int8   \n 6   answered_correctly              int8   \n 7   prior_question_elapsed_time     float32\n 8   prior_question_had_explanation  boolean\ndtypes: boolean(1), float32(1), int16(2), int32(1), int64(1), int8(3)\nmemory usage: 3.1 GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading questions data\nquestions = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\nquestions = questions.rename(columns = {'question_id':'content_id'})","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating train-test split\ndef get_train_split(X, y):\n    X_train , X_valid, y_train ,y_valid = train_test_split(X, y, train_size = train_ratio, \n                                                           test_size = test_ratio, random_state = random_seed)\n    return(X_train, X_valid, y_train, y_valid)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating lgbm model and training \ndef get_lgb(X_train, X_valid, y_train, y_valid):\n    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature = None)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, categorical_feature = None)\n    \n    #training\n    model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=10000,\n    early_stopping_rounds=8\n    )\n    return(model)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data imputer\ndef impute_num(data ,impute_strategy):\n    num_imputer = SimpleImputer(strategy=impute_strategy)\n    data_imputed = pd.DataFrame(num_imputer.fit_transform(data))\n    data_imputed.columns = data.columns\n    data_imputed.index = data.index\n    return(data_imputed)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocessing questions\n#Process Tags\n#Getting the tags out from the column\n\ndef process_tags(questions):\n    \n    tag = questions[\"tags\"].str.split(\" \", n = 6, expand = True) \n    tag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n    \n    #Conveting from string to numeric\n    tag['tags1'] = pd.to_numeric(tag['tags1'], errors='coerce')\n    tag['tags2'] = pd.to_numeric(tag['tags2'], errors='coerce')\n    tag['tags3'] = pd.to_numeric(tag['tags3'], errors='coerce')\n    tag['tags4'] = pd.to_numeric(tag['tags4'], errors='coerce')\n    tag['tags5'] = pd.to_numeric(tag['tags5'], errors='coerce')\n    tag['tags6'] = pd.to_numeric(tag['tags6'], errors='coerce')\n    \n    #imputing missing tag values \n    tag = tag.fillna(99999)\n    \n    drop_cols = ['tags','correct_answer']\n    \n    #Merging tags back to questions \n    questions = questions.drop(columns = drop_cols, axis = 1).join(tag)\n    \n    return questions","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature engineering\n#adding user features\nuser_df = train[train.answered_correctly != -1].groupby('user_id').agg({'answered_correctly': ['count', 'mean']}).reset_index()\nuser_df.columns = ['user_id', 'user_questions', 'user_mean']\n\nuser_lect = train.groupby([\"user_id\", \"answered_correctly\"]).size().unstack()\nuser_lect.columns = ['Lecture', 'Wrong', 'Right']\nuser_lect['Lecture'] = user_lect['Lecture'].fillna(0)\nuser_lect = user_lect.astype('Int64')\nuser_lect['watches_lecture'] = np.where(user_lect.Lecture > 0, 1, 0)\nuser_lect = user_lect.reset_index()\nuser_lect = user_lect[['user_id', 'watches_lecture']]\n\nuser_df = user_df.merge(user_lect, on = \"user_id\", how = \"left\")\ndel user_lect","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature engineering\n#adding content features \ncontent_df = train[train.answered_correctly != -1].groupby('content_id').agg({'answered_correctly': ['count', 'mean']}).reset_index()\ncontent_df.columns = ['content_id', 'content_questions', 'content_mean']","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sampling from train data due to RAM limitation\n#Preprocessing\ntrain_sample = train.sample(n = sample_size, random_state = random_seed).copy()\ndel(train)\ngc.collect()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"40"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaning up sampled data\ntrain_sample.prior_question_had_explanation = train_sample.prior_question_had_explanation*1 #converting boolean to number\ntrain_sample = train_sample.drop(train_sample[train_sample.answered_correctly == -1].index,axis = 0)  # removing lectures \ndrop_cols = ['user_answer','content_type_id']\ntrain_X = train_sample.drop(drop_cols, axis = 1)\ndel(train_sample)\ngc.collect()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting tag data \nquestions_tag_pr = process_tags(questions)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merging train data and tag data\ntrain_questions_X = train_X.merge(questions_tag_pr,on = 'content_id', how = 'left', suffixes = ('_left', '_right'))\n\ndel(train_X)\ngc.collect()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"20"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputing input data\ny = train_questions_X.answered_correctly\ndrop_cols = ['answered_correctly']\ntrain_questions_X = train_questions_X.drop(drop_cols, axis = 1)\ntrain_imp = train_questions_X.copy()\ntrain_imp.prior_question_elapsed_time = train_imp.prior_question_elapsed_time.fillna(0)\ntrain_imp.prior_question_had_explanation = train_imp.prior_question_had_explanation.fillna(1)\ntrain_imp = impute_num(train_imp ,num_imp_str)\n\n#Creating train, valid set \nX_train, X_valid, y_train, y_valid = get_train_split(train_imp, y)\ndel(train_questions_X, train_imp)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merging engineered features \n\nX_train = X_train.merge(user_df,on = 'user_id',how = 'left',suffixes=('_left', '_right'))\nX_valid = X_valid.merge(user_df,on = 'user_id',how = 'left',suffixes=('_left', '_right'))\nX_train = X_train.merge(content_df,on = 'content_id',how = 'left',suffixes=('_left', '_right'))\nX_valid = X_valid.merge(content_df,on = 'content_id',how = 'left',suffixes=('_left', '_right'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model\n#LGBM\nmodel = get_lgb(X_train, X_valid, y_train, y_valid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyzing LGBM Model\n#Feature importance\nlgb.plot_importance(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing env variables\nenv = riiideducation.make_env()\niter_test = env.iter_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions on test data  \n\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    test_df = test_df.set_index('row_id')\n    test_copy = test_df.copy()\n    \n    test_copy = test_copy.drop(test_copy[test_copy.content_type_id == 1].index,axis = 0)\n    drop_cols = ['prior_group_answers_correct','prior_group_responses','content_type_id']\n    test_copy = test_copy.drop(columns = drop_cols,axis = 1)\n    \n    test_copy.prior_question_had_explanation = test_copy.prior_question_had_explanation*1 #converting boolian to number\n\n    test_questions_X = test_copy.merge(questions_tag_pr,on = 'content_id', how = 'left', suffixes = ('_left', '_right'))\n    \n    test_copy_imp = test_questions_X.copy()\n    test_copy_imp.prior_question_elapsed_time = test_copy_imp.prior_question_elapsed_time.fillna(0)\n    test_copy_imp.prior_question_had_explanation = test_copy_imp.prior_question_had_explanation.fillna(1)\n\n\n    test_copy_imp = impute_num(test_copy_imp ,num_imp_str)\n\n    test_copy_imp = test_copy_imp.merge(user_df,on = 'user_id',how = 'left',suffixes=('_left', '_right'))\n    test_copy_imp = test_copy_imp.merge(content_df,on = 'content_id',how = 'left',suffixes=('_left', '_right'))\n    \n    pred = model.predict(test_copy_imp)\n    \n    df = pd.DataFrame({'row_id': test_copy.index, 'answered_correctly': pred})\n    df = df.set_index('row_id')\n    test_df = test_df.join(df)\n    test_df.answered_correctly.fillna(-1, inplace = True)\n    \n    \n    test_df = test_df.reset_index()\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}